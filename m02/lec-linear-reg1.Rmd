---
author: Derek Powell
title: "Bayesian Linear Regression"
subtitle: "PSY517 Quantitative Analysis III"
date: "Module 2"
output:
  beamer_presentation:
    keep_tex: no
    theme: metropolis
    latex_engine: lualatex
    slide_level: 2
    incremental: no
fontsize: 10pt
classoption: compress
header-includes:
  \setbeamercolor{frametitle}{bg=gray}
  \setbeamercolor{background canvas}{bg=white}
  \hypersetup{colorlinks, citecolor=orange, filecolor=red, linkcolor=brown, urlcolor=blue}
  \setbeameroption{show notes on second screen=right}
---

```{r setup, include=F}
knitr::opts_chunk$set(echo = FALSE, cache=TRUE)

library(tidyverse)
library(brms)
library(tidybayes)
library(modelr)
library(patchwork)

source("helpers.R")
bikes <- read_csv("../data/bikes.csv")

theme_set(theme_bw(base_size=10) + theme(panel.grid=element_blank()))
update_geom_defaults("point", list(shape = 1, size=1))
```

## Workflow

- propose model structure
- prior predictive checks
- fit model
- posterior predictive checks
- prediction, inference, etc.

# Proposing model structure

## Capital Bikeshare

> Capital Bikeshare is metro DC's bikeshare service, with 4,500 bikes and 500+ stations across 7 jurisdictions: Washington, DC.; Arlington, VA; Alexandria, VA; Montgomery, MD; Prince George's County, MD; Fairfax County, VA; and the City of Falls Church, VA. Designed for quick trips with convenience in mind, itâ€™s a fun and affordable way to get around.

We will consider a dataset that includes the total number of Capital Bikeshare rides from 500 separate days.

## Regression

- We are interested in relationship between the weather, specifically temperature, and rides
- We think rides is a _function_ of temperature. Roughly:

$$rides = f(temperature)$$

## Proposing a linear model

- We will assume $f$ is a linear function

$$rides = \alpha + \beta * temperature$$

- Let's draw what this might look like
- Will this assumption work?

:::notes
draw on board: 

- show impossible predictions (e.g. negative rides)
- willingness to predict for impossible values
:::

## Linear regression as geocentric model

- Can do a good job describing data generated by many different processes
- Not always (or often) good models of the true domain process
- Should not be taken too literally
  - They will happily make impossible predictions 

## Is a linear model appropriate?

- _temperature_ takes on a limited range of values
- _rides_ is bounded at zero in principle
  - But we know there are about 5000 rides per day on average, so may not be near zero

:::notes
So it seems reasonable rides will not often be near zero. 

If we ask our linear golem to make predictions about temperatures from neptune or venus (or wisconsin or phoenix) we could be in trouble. But as long as we don't blindly trust our golem, it could give a useful description and predictions
:::

## Linear model of rides and temperature

Let's begin with the __likelihood__ of our model:

<!--  -->
\begin{align*}
  y_i &\stackrel{iid}{\sim} Normal(\mu_i, \sigma) \\
  \mu_i &= \alpha + \beta x_i
\end{align*}
<!--  -->

In English this says: 

- Each observations $y_i$ will be distributed normally with mean $\mu_i$ and standard deviation $\sigma$. 
- Where $\mu_i$ is a linear function of the $x_i$ predictor values associated with each observation.

## Visualizing linear regression with a normal likelihood


\begin{align*}
  y_i &\stackrel{iid}{\sim} Normal(\mu_i, \sigma) \\
  \mu_i &= 0 + .5 x_i, \sigma = 1
\end{align*}



```{r normal-dist-reg-plot, fig.dim=c(3.5,2), fig.align='center'}
## borrowed from:
## https://stackoverflow.com/a/62553817/8297546
set.seed(234524)
x <- seq(-2.5,2.5,length.out=5)
y <- x*0.5

# x <- x - mean(x)
# y <- y - mean(y)

df <- data.frame(x, y)

# For every row in `df`, compute a rotated normal density centered at `y` and shifted by `x`
curves <- lapply(seq_len(NROW(df)), function(i) {
  mu <- df$y[i]
  range <- mu + c(-3, 3)
  seq <- seq(range[1], range[2], length.out = 100)
  data.frame(
    x = 1 * dnorm(seq, mean = mu) + df$x[i],
    y = seq,
    grp = i
  )
})

# Combine above densities in one data.frame
curves <- do.call(rbind, curves)

sim_obs_data <- tibble(
  x = sample(seq(-3,3,.1), size=200, replace=T),
  y = x*.5 + rnorm(200, 0, 1)
)

ggplot(mapping=aes(x, y)) +
  # geom_line() +
  geom_abline(slope=.5, intercept=0) +
  # The path draws the curve
  # geom_path(data = curves, aes(x=x, group = grp)) +
  # The polygon does the shading. We can use `oob_squish()` to set a range.
  geom_polygon(data = curves, aes(x=x, group = grp), alpha=.33, fill="blue") +
  geom_point(data = sim_obs_data)
```

## Extension: Heteroskedasticity

\begin{align*}
  y_i &\stackrel{iid}{\sim} Normal(\mu_i, \sigma_i) \\
  \mu_i &= 0 + .5x \\
  log(\sigma_i) &= .2 + .3x
\end{align*}


```{r heteroskedastic, fig.dim=c(3.5,2), fig.align='center'}
set.seed(23523)

x <- seq(-2.5,2.5, length.out=5)
y <-  .5*x

# x <- x - mean(x)
# y <- y - mean(y)

df <- data.frame(x, y)

# For every row in `df`, compute a rotated normal density centered at `y` and shifted by `x`
curves <- lapply(seq_len(NROW(df)), function(i) {
  mu <- df$y[i]
  range <- mu + c(-6, 6)
  seq <- seq(range[1], range[2], length.out = 100)
  data.frame(
    x = 1 * dnorm(seq, mean = mu, sd = exp(.2 + .3*df$x[i])) + df$x[i],
    y = seq,
    grp = i
  )
})

# Combine above densities in one data.frame
curves <- do.call(rbind, curves)

sim_obs_data <- tibble(
  x = sample(seq(-3,3,.01), size=200, replace=T),
  y = x*.5 + rnorm(200, 0, exp(.2 + .3*x))
)

ggplot(mapping=aes(x, y)) +
  # geom_line() +
  geom_abline(slope=.5, intercept=0) +
  # The path draws the curve
  # geom_path(data = curves, aes(x=x, group = grp)) +
  geom_polygon(data = curves, aes(x=x, group = grp), alpha=.33, fill="blue") +
  geom_point(data = sim_obs_data)
```

::: notes
- we'll work with some models like that later in the course
:::

## Is a normal likelihood appropriate for $y$?

- Capital Bike Share's members are able to take bikes for a ride for a fee
- The number of rides per day is the cumulative sum of all of the individual members' decisions to ride
- This is the kind of process that is likely to converge to an approximately normal distribution, via the _central limit theorem_.

## Simulating riders

Let's demonstrate to ourselves that a normal distribution could be appropriate for these data.
\scriptsize
```{r normal-sim, echo=T}
N <- 1000
trips <- 0:8
trip_probs <- c(.2, .05, .35, .15, .1, .05, .05, .03, .02)
ride_probs <- .5

person_trips <- sample(trips, N, replace=TRUE, prob=trip_probs)
person_rides <- rbinom(N, person_trips, ride_probs)
```

```{r, echo=T}
person_trips[1:20]
person_rides[1:20]
```


::: notes
- it's a membership model, so we have some number of members.
- each of them may have some number of trips they need to make during the day, let's say between 0 and 8
- they each have a probability of choosing to bike on each trip
- the probability they each choose to bike is a function of the weather; but we'll fix that here
:::

## Simulating riders: showing $y$ is plausibly normal
\small
```{r, echo=T, fig.dim=c(3,2), fig.align='center'}
sim_day <- function(){
  person_trips <- sample(trips, N, replace=TRUE, prob=trip_probs)
  person_rides <- rbinom(N, person_trips, ride_probs)
  sum(person_rides)
}

gghist(replicate(5000, sim_day()), binwidth=5)
```

::: notes
- This is a plausible story, but we can't evaluate it here since all we have measured is total rides. This is what McElreath means by saying gaussian distributions cannot reliably identify "microprocesses"
:::

# Priors and prior predictive checks

## Priors

For our model:

\begin{align*}
  y_i &\stackrel{iid}{\sim} Normal(\mu_i, \sigma) \\
  \mu_i &= \alpha + \beta x_i
\end{align*}


We will we need priors for $\alpha$, $\beta$, and $\sigma$

## Types of priors

- Uninformative priors
- Weakly informative priors
- Informative priors

But there are no such thing as "correct" or "true" priors

::: notes
- there is no "correct" prior
- these approaches lie on a continuum
- in this course we will focus on the latter two
:::

## Generic weakly informative priors

- For linear regression: priors defined on standardized variables
- Restricts to "reasonable" range of parameter values, but without incorporating any specific information
- One possible example would be:


\begin{align*}
  \alpha &\sim Normal(0, 3) \\
  \beta &\sim Normal(0, 3) \\
  \sigma &\sim HalfCauchy(5)
\end{align*}


::: notes
we'll see what this looks like later
:::

## Developing informative priors

### What domain knowledge do we have or can we get?

- Start knowing that the average number of rides per day is about 5000
- Will cooler temperatures lead more people to ride or fewer?
  - What range of temperatures are typical in D.C.?

:::notes
- informative priors based on our knowledge BEFORE we see the data

- In PHX higher temperatures would probably mean fewer riders. In D.C. it's less clear. It does get pretty cold, but average Jan highs are 40 degrees, which might be more pleasant for a ride than 90 degrees.
:::


## Proposing informative priors

I'll start by proposing the following priors based on what I know so far about these data


\begin{align*}
  \alpha &\sim Normal(5000, 2000) \\
  \beta &\sim Normal(150, 300) \\
  \sigma &\sim Exponential(1/250)
\end{align*}


We'll evaluate and possibly improve these priors in a moment.

::: notes
- I know $\alpha$ should be about 5000 but I'm not sure how confident I can be
- I think $\beta$ will be positive but it could be negative too, and I don't know how large a number it will be
- I'm not sure what $\sigma$ will be, but the expectation of an exponential is the inverse of its rate parameter (so 250 here)
:::

# Bayesian regression in `brms`

## The `brms` package

We will use the `brms` package to fit all of the Bayesian regression models we will learn about in this class.

### Why `brms` ?
- `brms` supports nearly any model you could ever wish, all within a single common syntax and with many additional helpful functions.

### Why not `brms`?
- Fitting models with `brms` is slower than with functions like `lm()`

## Centering

$$\mu_i = \alpha + \beta x_i$$

- $\alpha$ represents the expected value of $\mu_i$ when the temperature is 0, but D.C. never really reaches 0Â° Fahrenheit
- Centering predictors $x_i$ as $x_i-\bar{x}$ let's $\alpha$ represents the number of rides on an average temperature day, rather than a 0Â° day.
- Conveniently, `brms` does this centering for us internally, and will interpret a prior set on the intercept term relative to the centered predictors

## Some candidate informative priors

Recall our initial proposal for priors 


\begin{align*}
  \alpha &\sim Normal(5000, 2000) \\
  \beta &\sim Normal(150, 300) \\
  \sigma &\sim Exponential(1/250)
\end{align*}


Let's evaluate these priors.

::: notes
- I know $\alpha$ should be about 5000 but I'm not sure how confident I can be
- I think $\beta$ will be positive but it could be negative too, and I don't know how large a number it will be
- I'm not sure what $\sigma$ will be, but the expectation of an exponential is the inverse of its rate parameter (so 250 here)
:::

## Loading the `bikes` data

We haven't even loaded the data yet because priors need to come "prior" to the data: Your priors should be based on general domain knowledge and __not__ on the data you are analyzing. 

But, to set up our model we will need to load the data.

```{r read-bikes, echo=T, message=F}
bikes <- read_csv("../data/bikes.csv")
```

::: notes

- With informative priors must come before data
- But with weakly informative it could be ok to look at the data to get a sense of the scale that the data is on
:::

## `brms` model syntax

Let's translate our model into `brms` syntax:

:::::::::::::: {.columns}
::: {.column width="40%"}
### Model

\small 


\begin{align*}
  y_i &\stackrel{iid}{\sim} Normal(\mu_i, \sigma) \\
  \mu_i &= \alpha + \beta x_i \\
  \alpha &\sim Normal(5000, 2000) \\
  \beta &\sim Normal(150, 300) \\
  \sigma &\sim Exponential(1/250)
\end{align*}


\normalsize

:::
::: {.column width="60%"}
### `brms` syntax
\scriptsize
```r
fit <- brm(
  rides ~ temp_feel,
  prior = 
    prior(normal(5000, 2000), class="Intercept") +
    prior(normal(300, 300), coef="temp_feel") +
    prior(exponential(.004), class="sigma"),
  family = gaussian(),
  data = bikes
  )
```

:::
::::::::::::::

## `brms` defaults

That may look like a lot of code, but `brms` models can be specified more simply with the built-in defaults.

```r
fit_default <- brm(rides ~ temp_feel, data = bikes)
```

- By default, `brms` assumes that `rides` is normally distributed and will use uninformative default priors that do not incorporate any domain knowledge. 
- Generally in this course we will specify meaningful priors, but this can be used to approximate a default "frequentist" or maximum-likelihood estimate. 
- We'll talk more about that in a few lectures.

## Plotting priors

It can be tough to come up with numbers to represent our beliefs, especially as you are getting familiarized with different probability distributions. 

But it's easier if you plot things:

```{r plot-prior1-params, message = F, fig.dim=c(7,2), fig.align='center'}
library(tidyverse)
library(patchwork)
(ggplot() + 
  geom_line(
    aes(x = seq(-5000, 15000, 1), y= dnorm(seq(-5000, 15000, 1), 5000, 2500))
    ) +
  labs(y="Density", x = expression(alpha)) +

ggplot() + 
  geom_line(
    aes(x = seq(-1500, 1500, 1), y= dnorm(seq(-1500, 1500, 1), 150, 300))
    ) +
  labs(y="Density", x = expression(beta)) +

ggplot() + 
  geom_line(
    aes(x = seq(.1, 3000, 1), 
        # y = exp(dnorm(seq(.1, 1000, 1), 0, 1000)))
        y = dexp(seq(.1, 3000, 1), 1/500))
        # y = dcauchy(seq(.1, 1000, 1), 0, 500))
    ) +
  labs(y="Density", x = expression(sigma)) )
```

What do you see?

::: notes
- $\alpha$ is allowing intercept values below zero, but we know that can't be right
:::

## Revising the prior

- Maybe we should tighten up our prior on $\alpha$
- Let's change it to $Normal(5000, 1000)$

```{r plot-prior2-params, message = F, fig.dim=c(7,2), fig.align='center'}
(ggplot() + 
  geom_line(
    aes(x = seq(-5000, 15000, 1), y= dnorm(seq(-5000, 15000, 1), 5000, 1000))
    ) +
  labs(y="Density", x = expression(alpha)) +

ggplot() + 
  geom_line(
    aes(x = seq(-1500, 1500, 1), y= dnorm(seq(-1500, 1500, 1), 300, 300))
    ) +
  labs(y="Density", x = expression(beta)) +

ggplot() + 
  geom_line(
    aes(x = seq(.1, 3000, 1), 
        # y = exp(dnorm(seq(.1, 1000, 1), 0, 1000)))
        y = dexp(seq(.1, 3000, 1), 1/250))
        # y = dcauchy(seq(.1, 1000, 1), 0, 500))
    ) +
  labs(y="Density", x = expression(sigma)) ) 
```

## Prior predictive

- We are trying to encode our domain knowledge into priors for the parameters of our model
- Usually it is easier if we think in terms of the data we'd expect to observe, rather than parameters
- To do this we can create and visualize the prior predictive

## Generating prior predictive

Setting the option `sample_prior = "only"` will sample from the prior specified for the model without conditioning on the data.

\small

```{r brm-prior1, echo=T, message=F, warning=F, results='hide'}
fit_prior1 <- brm(
  rides ~ temp_feel,
  prior = 
    prior(normal(5000, 1000), class="Intercept") +
    prior(normal(300, 300), coef="temp_feel") +
    prior(exponential(.004), class="sigma"),
  family = gaussian(),
  data = bikes,
  sample_prior = "only"
  )
```

## Plotting prior predictive

\small

```{r plot-prior1-brm, echo=T, fig.dim=c(4,2), fig.align='center'}
set.seed(234232)

data_grid(bikes, temp_feel = seq_range(temp_feel, n=2)) %>% 
  add_epred_draws(fit_prior1, ndraws=25) %>% 
  ggplot(aes(x=temp_feel, y = .epred, group=.draw)) +
  geom_line(alpha=.25) +
  geom_hline(yintercept=0)
```

- when we actually look at things on the scale of the data we realize things are out of whack
- quite a few lines predicting below zero rides for most of the observed data range
- and some far-out predictions like -20,000 rides

## Breaking down the code

The first line calls the `data_grid()` and `seq_along()` functions from the `modelr` package

```{r, echo=T}
data_grid(bikes, temp_feel = seq_range(temp_feel, n=2))
```

## Breaking down the code (2)

Then we take that output and pipe it into the `add_epred_draws()` function from the `tidybayes` package.

```r
... %>%
  add_epred_draws(fit_prior1, ndraws=25) 
```
\small
```{r}
data_grid(bikes, temp_feel = seq_range(temp_feel, n=2)) %>% 
  add_epred_draws(fit_prior1, ndraws=25) %>% 
  head(6)
```

## Breaking down the code (3)

And finally we plot

```r
... %>% 
  ggplot(aes(x=temp_feel, y = .epred, group=.draw)) +
  geom_line(alpha=.25) +
  geom_hline(yintercept=0)
```

::: notes
- explain data_grid
- explain adding draws
:::

## `tidybayes::add_*_draws()`

We will use several functions from the `tidybayes` package to access different types of samples from our models.

Right now we have two sources of uncertainty in our model:

1. Uncertainty in the parameters
2. Uncertainty in the observed values 

- `add_predicted_draws()`: Add draws from the prior or posterior predictive.
  - These are predicted _observations_ containing both sources of uncertainty
- `add_epred_draws()`: Add draws from the expectation of the prior/posterior predictive
  - These are the predicted values of our regression line, with only the uncertainty in the model parameters

## Revising the prior

This prior on $\beta$ was too wide, so let's reign it in a bit. Now the prior is:

\begin{align*}
  \alpha &\sim Normal(5000, 1000) \\
  \beta &\sim Normal(100, 100) \\
  \sigma &\sim Exponential(1/250)
\end{align*}


```{r brm-prior2, message=F, results='hide'}

fit_prior2 <- update(
  fit_prior1,
  prior = 
    prior(normal(5000, 1000), class="Intercept") +
    prior(normal(100, 100), coef="temp_feel") +
    prior(exponential(.004), class="sigma"),
  sample_prior = "only"
  )

```

```{r plot-brm-prior2, fig.dim=c(4,2), fig.align='center'}
set.seed(2352352)
data_grid(bikes, temp_feel = seq_range(temp_feel, n=2)) %>%
  add_epred_draws(fit_prior2, ndraws=25) %>%
  ggplot(aes(x=temp_feel, y = .epred, group=.draw)) +
  geom_line(alpha=.25) +
  geom_hline(yintercept=0)
```

This looks more plausible.

## Simulating the prior predictive values

The plot below shows $n=50$ simulated observations at the expected values of our prior.

\scriptsize
```{r sim-bikes-data, echo=T, fig.dim=c(3,1.5), fig.align='center'}
N <- 50; set.seed(12345)
tibble(
  temperature = seq(40, 90, length.out=N),
  rides = rnorm(N, mean = 5000 + center(temperature) * 100, sd = 250)
) %>% 
  ggplot(aes(x=temperature, y = rides)) + geom_point() 
```

\normalsize

This looks too orderly. It would be great if temperature was such a strong predictor, but things are likely a bit noisier than this.

::: notes
- We can also get a sense of things by simulating observations.
- It can often be a good idea to propose a prior and then spread it out a bit
:::

## Simulating data manually 

Let's update the prior on $\sigma$ to $Exponential(1/1000)$ and simulate some new data using our new expected value of $\sigma$.

```{r sim-bikes-data2,  echo=F, fig.dim=c(3,1.5), fig.align='center'}
simd <- tibble(
  temperature = seq(40, 90, length.out=N),
  rides = rnorm(
    N, 
    mean = 5000 + center(temperature) * 100, 
    sd = 1000
    )
)

simd %>% 
  ggplot(aes(x=temperature, y = rides)) + 
  geom_point()
```

That looks more plausible. 

:::notes
Simulating data like this can be a good way to get a quick sense of how a model functions and what kinds of data it corresponds to.

Simulating data can also be useful when we want to know whether we will be able to meaningfully estimate parameters in our statistical models, especially when models become very complex or novel
:::

## Simulated observations from the prior predictive

We can check things more formally too using the full prior predictive generated by `brms`. Here are 9 simulated datasets.

```{r brm-prior3, message=F, results='hide'}
fit_prior3 <- update(
  fit_prior2,
  prior = 
    prior(normal(5000, 1000), class="Intercept") +
    prior(normal(100, 100), coef="temp_feel") +
    prior(exponential(.001), class="sigma"),
  sample_prior = "only"
  )
```

:::::::::::::: {.columns}
::: {.column width="40%" align=center}
\scriptsize
```r
set.seed(2352353)
data_grid(
  bikes,
  temp_feel = sample(temp_feel, 50)
) %>% 
add_predicted_draws(
  fit_prior3, 
  ndraws=16
  ) %>% 
ggplot(
  aes(
    x=temp_feel, 
    y = .prediction
    )
) +
geom_point() +
facet_wrap(~.draw)
```

:::
::: {.column width="60%" align=center}

```{r brm-sim-data, fig.dim=c(2.5, 2.5), fig.align='center'}
set.seed(2352353)
bikes %>% 
  data_grid(temp_feel = sample(temp_feel, 50)) %>% 
  add_predicted_draws(fit_prior3, ndraws=9) %>% 
  ggplot(aes(x=temp_feel, y = .prediction)) +
  geom_point() +
  facet_wrap(~.draw) +
  theme_bw(base_size=8) +
  theme(panel.grid=element_blank())
```

:::
::::::::::::::

::: notes
- You can see a lot of simulated datasets have very low variance. That makes sense if you think about the shape of the prior we put on $\sigma$ using an exponential distribution, the most probable value is zero.
- Here it can be ok to let one fact about the data inform us: we have a good amount of data (500 obs), and every single datapoint informs about sigma. So even if our prior is biased toward values we think are implausibly small, as long as we allow for large values, we can be pretty confident our posterior will be accurate.
:::

## Comparison with weakly informative priors

```{r brm-weak-prior, message=F, results='hide'}
fit_prior_wi <- brm(
  rides ~ standardize(temp_feel),
  prior = 
    prior(normal(0, 3), class="Intercept") +
    prior(normal(0, 3), coef="standardizetemp_feel") +
    prior(cauchy(0, 5), class="sigma"),
  family = gaussian(),
  data = bikes %>% 
    mutate(rides = standardize(rides)),
  sample_prior = "only"
  )
```

```{r, fig.align='center', fig.dim=c(3,2)}
set.seed(2364)
data_grid(bikes, temp_feel = seq_range(temp_feel, n=2)) %>% 
  add_epred_draws(fit_prior_wi, ndraws=50) %>% 
  mutate(.epred = unstandardize(.epred, bikes$rides)) %>% 
  ggplot(aes(x=temp_feel, y = .epred, group=.draw)) +
  geom_line(alpha=.25) +
  geom_hline(yintercept=0)
```

::: notes
- equally positive and negative slopes
- substantial number nearly always below zero (didn't use any prior info on intercept)
:::


# Fitting the model

Now we are satisfied with our prior, we are ready to estimate the posterior of the model.

:::::::::::::: {.columns}
::: {.column width="40%"}
### Model

\small 

\begin{align*}
  y_i &\stackrel{iid}{\sim} Normal(\mu_i, \sigma) \\
  \mu_i &= \alpha + \beta x_i \\
  \alpha &\sim Normal(5000, 1000) \\
  \beta &\sim Normal(100, 100) \\
  \sigma &\sim Exponential(1/250)
\end{align*}

\normalsize

:::
::: {.column width="60%"}
### `brms` syntax
\scriptsize
```r
fit <- brm(
  rides ~ temp_feel,
  prior = 
    prior(normal(5000, 1000), class="Intercept") +
    prior(normal(100, 100), coef="temp_feel") +
    prior(exponential(.001), class="sigma"),
  family = gaussian(),
  data = bikes
  )
```

:::
::::::::::::::


```{r brm-fit-model, message=F, results='hide'}
# fit <- brm(
#   rides ~ temp_feel_centered,
#   prior = 
#     prior(normal(5000, 2000), class="Intercept") +
#     prior(normal(0, 100), coef="temp_feel_centered") +
#     prior(exponential(.001), class="sigma"),
#   family = gaussian(),
#   data = bikes %>% 
#     mutate(temp_feel_centered),
#   sample_prior = "yes"
#   )

fit <- update(fit_prior3, recompile=FALSE, sample_prior='yes') # can just update
```

## Markov Chain Monte Carlo

- We use `brms` to ask our computer to compute a posterior probability distribution
- The estimate is made with a method called Markov Chain Monte Carlo (MCMC)
- We will leave MCMC behind an __abstraction layer__
  - `brms` does a very good job setting up MCMC, so it usually works fine
  - But there are a few diagnostics we will check to make sure things have gone smoothly

::: notes
- No one can know everything. 
- We will make use of an "abstraction layer"
:::

## Model fitting diagnostics

Before we look at our results we need to check whether the model fit properly

### Three things to look out for

1. Divergent transitions: should be zero
2. $\hat{R}$ statistic: should be 1.0 (up to 1.01 can be ok)
3. Effective sample size (ESS): should be at least about 500 for all parameters

::: notes
Failing these diagnostics signals a PROBLEM. We will worry about how to fix those problems later, once we run into some.
:::


## Quick diagnostics with `summary()`
\scriptsize
```{r fit-summary-checks, echo=T}
summary(fit)
```

# Posterior predictive checks

## Inspecting our posterior fit

```{r prior-v-posterior, fig.dim=c(8,4), fig.align='center'}
set.seed(23262)

data_grid(bikes, temp_feel = seq_range(temp_feel, n=2)) %>% 
  add_epred_draws(fit_prior3, ndraws=25) %>% 
  mutate(distribution = "Prior") %>% 
  bind_rows(
    data_grid(bikes, temp_feel = seq_range(temp_feel, n=2)) %>% 
    add_epred_draws(fit, ndraws=25) %>% 
    mutate(distribution = "Posterior") 
  ) %>% 
  mutate(distribution = ordered(distribution, levels=c("Prior","Posterior"))) %>% 
  ggplot(aes(x=temp_feel, y = .epred, group=.draw)) +
  geom_line(alpha=1/4) +
  facet_wrap(~distribution) +
  theme_bw(base_size=16) +
  theme(panel.grid=element_blank()) +
  labs(x="Temperature", y = "Expected prediction")
```

## Checking the distribution

\small
```{r pp_check, echo=T, message=F, fig.dim=c(5,2), fig.align='center'}
pp_check(fit, type="dens_overlay") + 
  pp_check(fit, type="ecdf_overlay")
```

## Checking predictions
\scriptsize
```{r pp-scatter-check, echo=T, message=F, fig.dim=c(3.5,1.5), fig.align='center'}
data_grid(bikes, temp_feel) %>% 
  add_predicted_draws(fit, ndraws=1000) %>% # comes out grouped by .row
  summarize(
    .pred = mean(.prediction), 
    .lower = quantile(.prediction, .025), 
    .upper = quantile(.prediction, .975)
    ) %>%  
  ggplot(aes(x=temp_feel, y = .pred)) +
  geom_line() +
  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha=1/4) +
  geom_point(data=bikes, aes(y=rides)) 
```

```{r, include=F}

bikes %>% 
  add_pred_interval(fit) %>% 
  ggplot(aes(x=temp_feel, y = rides)) +
  geom_line(aes(y=.pred)) +
  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha=1/4) +
  geom_point(data=bikes) 

```


```{r, include=F}
bikes %>% 
  add_epred_interval(fit) %>% 
  ggplot(aes(x=temp_feel, y = rides)) +
  geom_line(aes(y=.epred)) +
  geom_ribbon(aes(ymin=.lower, ymax=.upper), alpha=1/4) +
  geom_point(data=bikes) 
```

## Weakly informative priors to posterior

- Our posterior looks the same with the weakly informative priors, so our informative priors aren't doing all that much here.
- But that's good! It means we have enough data.

```{r, include=F}
fit_wi <- update(fit_prior_wi, recompile=FALSE, sample_prior="yes")
```

```{r, fig.align='center', fig.dim=c(7,3.5)}
bikes %>% 
data_grid(temp_feel = seq_range(temp_feel, n=2)) %>% 
  add_epred_draws(fit_prior_wi, ndraws=25) %>% 
  mutate(distribution = "Prior") %>% 
  bind_rows(
    bikes %>% 
    data_grid(temp_feel = seq_range(temp_feel, n=2)) %>% 
    add_epred_draws(fit_wi, ndraws=25) %>% 
    mutate(distribution = "Posterior") 
  ) %>% 
  mutate(distribution = ordered(distribution, levels=c("Prior","Posterior"))) %>% 
  mutate(.epred = unstandardize(.epred, bikes$rides)) %>% 
  ggplot(aes(x=temp_feel, y = .epred, group=.draw)) +
  geom_line(alpha=1/4) +
  facet_wrap(~distribution) +
  theme_bw(base_size=16) +
  theme(panel.grid=element_blank()) +
  labs(x="Temperature", y = "Expected prediction")
```


# Inference and prediction

## Inference

Now we are satisfied with our model, we can inspect its parameters.

\scriptsize

```{r fit-summary, echo=T}
summary(fit)
```

::: notes
- note that intercept values being reported to us are the uncentered values--for when the temp is 0F
- by default have 95% CI of parameters
:::

## Posterior parameter samples

:::::::::::::: {.columns}
::: {.column}
\scriptsize
```{r extract-posterior-samples, echo=T}
posterior_samps <- 
  posterior_samples(fit) %>% 
  select(-lp__)
head(posterior_samps)
```

:::
::: {.column}
\scriptsize
```{r beta-hist, echo=T, fig.dim=c(2,2)}
posterior_samps %>% 
  ggplot(aes(x=b_temp_feel)) +
  geom_histogram(binwidth=1)
```

:::
::::::::::::::

## Prediction

- How many rides do we predict we'll observe on a 90Â° F day?

```{r pp90, fig.dim=c(3,1.5)}
tibble(temp_feel = 90) %>% 
  add_predicted_draws(fit) %>% 
  ggplot(aes(x=.prediction)) +
  geom_histogram(bins=100)
```

- How about a 0Â° F day?
- If we push our predictions too far outside the range of observed values, bad things can happen

## Using predictions to make decisions

- We need to choose a day to pull out 20% of our bikes to do maintenance
- On that day, we will not be able to support more than 5500 rides, so any rides we might have had beyond 5500 represent lost revenue, which we want to minimize
- Assume riders are charged a flat fee of $5.00 per ride

::: notes
- this is not 100% realistic of course
- also because very few businesses are actually this data-driven
:::

## Using predictions to make decisions

- Suppose today we know that the temperature will feel like 81Â° F.
- What is the probability that we do not lose any revenue if we do the maintenance today?

\scriptsize

```{r pred81-rides, echo=T}
post_pred <- tibble(temp_feel=81) %>% 
  add_predicted_draws(fit)

mean(post_pred$.prediction < 5500)
```

```{r, include=F, fig.dim=c(3,2), fig.align='center'}

post_pred %>% 
  mutate(losing = if_else(.prediction > 5500, "yes", "no")) %>% 
  ungroup() %>% 
  ggplot(aes(x=.prediction, fill=losing)) +
  geom_histogram(bins=101) +
  scale_fill_manual(values=c("grey","skyblue")) +
  theme_bw() +
  labs(x = "Predicted rides", fill="Lose Revenue")
```

## Using predictions to make decisions

How much revenue should we expect to lose if we do the maintenance today?

\scriptsize

```{r, echo=T}
post_pred %>% 
  ungroup() %>% 
  mutate(
    lost_trips = if_else(.prediction < 5500, 0, .prediction - 5500),
    lost_revenue = lost_trips*5.00
    ) %>% 
  summarize(
    expected_trip_loss = mean(lost_trips),
    expected_rev_loss = mean(lost_revenue)
  )
```

## Using predictions to make decisions with uncertainty

- Rather than do the maintenance today, we could also do the maintenance next week
- The forecast says there's a 70% chance of rain coming that will cool things off next week, but otherwise it will be even hotter.
- The plot below visualizes the weather forecast: the rains will bring temps around 70Â° F, but without the rains we can expect to reach 90Â° F

```{r weather-forcast, fig.dim=c(3,2), fig.align='center'}
p_grid <- seq(0, 150, by=.5)
prob <- dnorm(p_grid, 70, 1)*.70 + dnorm(p_grid, 90, 1)*.30
weather_samples <- sample(p_grid, 1e4, replace=TRUE, prob = prob/sum(prob))

ggplot() + 
  geom_histogram(aes(x=weather_samples), binwidth=.5) +
  theme_bw() +
  labs(x = "Forecasted temperature")
```

## Using predictions to make decisions with uncertainty (2)

We compute the posterior predictive just as we did before.

```{r, echo=T}
post_pred_delay <- tibble(temp_feel = weather_samples) %>% 
  sample_n(500) %>%
  add_predicted_draws(fit) 
```

::: notes
The shape of the posterior looks normal, but that is just because of the uncertainty in the model and the forecasted weather distributions overlap sufficiently.
:::

And we can compare the predictions for waiting to acting today:

\scriptsize
```{r}
post_pred %>% 
  mutate(
    lost_trips = if_else(.prediction < 5500, 0, .prediction - 5500),
    lost_revenue = lost_trips*5.00
    ) %>% 
  ungroup() %>% 
  summarize(
    expected_trip_loss = mean(lost_trips),
    expected_rev_loss = mean(lost_revenue),
    losses_upper_99 = quantile(lost_revenue, .99)
  )

post_pred_delay %>% 
  mutate(
    lost_trips = if_else(.prediction < 5500, 0, .prediction - 5500),
    lost_revenue = lost_trips*5.00
    ) %>% 
  ungroup() %>% 
  summarize(
    expected_trip_loss = mean(lost_trips),
    expected_rev_loss = mean(lost_revenue),
    losses_upper_99 = quantile(lost_revenue, .99)
  )

```

## Optimizing decisions

- We expect to lose less revenue by waiting a week
- But note that our worst-case scenario revenue losses look worse if we wait
- If these were actual costs rather than revenue, we might care more about mitigating our worst-case-scenario risk 
- Working with posterior samples let's us have all this information

# Exercises

## Hands-on: Simulating data manually

Explore further to see whether these priors seem reasonable by simulating some more data.

- How do things look if $\beta$ is two SD above or below the mean?
- What if $\alpha$ is one SD lower than expected, $\beta$ is two SD greater than expected, and $\sigma$ is 2000?
  - What is the probability that these or more extreme conditions obtain?
  - Recall, our prior parameters are independent
  - Hint: use `rnorm()` and `rexp()` to estimate with samples, or `pnorm()` and `pexp()` to estimate directly
  
```{r, include=F}
simd <- tibble(
  temperature = seq(40, 90, length.out=N),
  rides = rnorm(N, mean = 4000 + center(temperature) * 300, sd = 2000)
)

simd %>% 
  ggplot(aes(x=temperature, y = rides)) + 
  geom_point()
```


# Extra slides


## Matching equations and code

- $y_i \stackrel{iid}{\sim} Normal(\mu_i, \sigma)$
  - `family = gaussian()`
- $\mu_i = \alpha + \beta x_i$
  - `rides ~ temp_feel`
- $\alpha \sim Normal(5000, 2500)$
  - `prior(normal(5000, 2000), class="Intercept")`
- $\beta \sim Normal(300, 300)$
  - `prior(normal(300, 300), coef="temp_feel")`
- $\sigma \sim Exponential(1/250)$
  - `prior(exponential(.004), class="sigma")`

